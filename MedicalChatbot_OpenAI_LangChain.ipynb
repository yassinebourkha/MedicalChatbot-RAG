{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5vKwdyDHoO1H",
        "4ZRKRzm3qRKY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Chatbot with Retrieval-Augmented Generation (RAG)\n",
        "\n",
        "This Jupyter Notebook demonstrates how to build a Retrieval-Augmented Generation (RAG) medical chatbot. RAG is a powerful approach that combines language models with a retrieval component to enhance responses by incorporating information from a knowledge base. This setup is particularly useful for domains like healthcare, where accurate and factual information is essential."
      ],
      "metadata": {
        "id": "w-Rt8UJ8oo4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importing Libraries\n",
        "\n",
        "We begin by importing the necessary libraries:\n",
        "- **`langchain`**: Used to manage prompt templates, chains, and memory for conversational contexts.\n",
        "- **`OpenAI`**: Provides the language model for response generation."
      ],
      "metadata": {
        "id": "iiftrHa1ozZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "langchain\n",
        "langchain-community\n",
        "langchain-openai\n",
        "pypdf\n",
        "langchain-chroma\n",
        "gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PMHhFYcPEJk",
        "outputId": "5616599c-b714-4216-c47e-6f7505a6e949"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r  requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehE7yKJlPF9E",
        "outputId": "9204f8c0-fd4d-4f75-cc47-ea55dd5ec8a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain import hub\n",
        "from google.colab import userdata\n",
        "import os"
      ],
      "metadata": {
        "id": "y_eJTJu2pT07"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Setting Up Environment Variables\n",
        "To interact with the OpenAI API, you need an API key. The code snippet below fetches the API key stored as an environment variable. Ensure the variable OPENAI_API_KEY is set in your environment for the chatbot to function correctly."
      ],
      "metadata": {
        "id": "5vKwdyDHoO1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "cp-pueTrOd51"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Indexing"
      ],
      "metadata": {
        "id": "MaE2p9VopmwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by preparing our documents for retrieval using embeddings and vector storage."
      ],
      "metadata": {
        "id": "-tp7ew_br_wy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Load"
      ],
      "metadata": {
        "id": "K25-amp9p7oT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we load medical literature from a PDF file. The document used here is **The GALE Encyclopedia of Medicine**, which provides reliable medical information that the chatbot will draw upon when answering questions.\n",
        "\n",
        "You can upload this or other medical documents to provide a robust foundation for the chatbot's responses."
      ],
      "metadata": {
        "id": "22vVUIyFsFFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "-vy9Wx6RQL7N",
        "outputId": "706f515a-be52-44bc-9c00-cda7ca338e07"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0e91ad10-1f6e-4989-a959-d58bcef33807\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0e91ad10-1f6e-4989-a959-d58bcef33807\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.pdf to data.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(path):\n",
        "  loader = PyPDFLoader(file_path=path)\n",
        "  pages = loader.load_and_split()\n",
        "  return pages"
      ],
      "metadata": {
        "id": "CB6w1gjGPtnB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/data.pdf\"\n",
        "pages =load_documents(data_path)"
      ],
      "metadata": {
        "id": "PDOJznewRVyz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pages[50].page_content)"
      ],
      "metadata": {
        "id": "O3-CE8zWResQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Split"
      ],
      "metadata": {
        "id": "PdNcIztoqC-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The documents are split into chunks to make the retrieval process more efficient. This allows for targeted responses to user queries."
      ],
      "metadata": {
        "id": "pkweQTFPspl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_split(document, chunk_size = 1000, chunk_overlap = 0):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size = chunk_size, chunk_overlap =  chunk_overlap)\n",
        "  text_splitted = text_splitter.split_documents(document)\n",
        "  return text_splitted"
      ],
      "metadata": {
        "id": "Zl1zr_vuR7E3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitted = text_split(pages)"
      ],
      "metadata": {
        "id": "eJs3xtVETAuK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_splitted[1500].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9T8e-gzTNEi",
        "outputId": "cfcf08e1-9514-42a9-8c96-93fb5b9cc39d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agoraphobic Foundation of Canada. P.O. Box 132, Chomedey,\n",
            "Laval, Quebec. H7W 4K2, Canada.\n",
            "Agoraphobics In Motion. 605 W. 11 Mile Rd., Royal Oak, MI\n",
            "48067. (248) 547-0400.\n",
            "American Psychiatric Association. 1400 K Street NW, Washing-\n",
            "ton DC 20005. (888) 357-7924. <http://www.psych.org>.\n",
            "Anxiety Disorders Association of America. 11900 Parklawn\n",
            "Dr., Ste. 100, Rockville, MD 20852. (301) 231-9350.\n",
            "<http://www.adaa.org>.\n",
            "National Alliance for the Mentally Ill (NAMI). Colonial Place\n",
            "Three, 2107 Wilson Blvd., Ste. 300, Arlington, V A 22201-\n",
            "3042. (800) 950-6264. <http://www.nami.org>.\n",
            "National Anxiety Foundation. 3135 Custer Dr., Lexington, KY\n",
            "40517. (606) 272-7166. <http://www.lexington-on-line.\n",
            "com/naf.html>.\n",
            "National Institute of Mental Health. Mental Health Public\n",
            "Inquiries, 5600 Fishers Lane, Room 15C-05, Rockville,\n",
            "MD 20857. (888) 826-9438. <http://www.nimh.nih.gov>.\n",
            "National Mental Health Association. 1021 Prince St., Alexan-\n",
            "dria, V A 22314. (703) 684-7722. <http://www.nmha.org>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Store"
      ],
      "metadata": {
        "id": "I7JKEoSJqHWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create embeddings of our text chunks and store them in a vector database. This allows us to search for similar content efficiently."
      ],
      "metadata": {
        "id": "vLIvPJq2sy5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "db = Chroma.from_documents(text_splitted, embeddings)"
      ],
      "metadata": {
        "id": "_eo4BpmeUb3d"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Retrieval and Generation"
      ],
      "metadata": {
        "id": "4ZRKRzm3qRKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the indexed documents, we can now retrieve relevant information and generate responses based on user questions."
      ],
      "metadata": {
        "id": "J6Q6KYQqs70i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Retrieve"
      ],
      "metadata": {
        "id": "wgozOxGXqaz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set up a retriever to find content related to a user's query based on similarity with stored embeddings."
      ],
      "metadata": {
        "id": "Gub_eNUTtJcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever(search_type= \"similarity\")"
      ],
      "metadata": {
        "id": "kpzlAqEnqXUh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = retriever.invoke(\"what's diabetes\")"
      ],
      "metadata": {
        "id": "hlAnfySWVkEc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(question)):\n",
        "  print(f\"the {i+1}th similar content :\\n \\n {question[i].page_content}\\n \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKxzc5lPVlAV",
        "outputId": "a6daa31f-6d75-460a-898c-2ee0523b487c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 1th similar content :\n",
            " \n",
            " about 10 years after the beginning of diabetes. In the Unit-\n",
            "ed States, new cases of blindness are most often caused by\n",
            "diabetic retinopathy. Among these new cases of blindness,\n",
            "12% are people between the ages of 20 to 44 years, and\n",
            "19% are people between the ages of 45 to 64 years.\n",
            "Causes and symptoms\n",
            "There are many causes of retinopathy. Some of the\n",
            "more common ones are listed below.\n",
            "Diabetic retinopathy\n",
            "Diabetes is a complex disorder characterized by an\n",
            "inability of the body to properly regulate the levels of\n",
            "sugar and insulin (a hormone made by the pancreas) in the\n",
            "blood. As diabetes progresses, the blood vessels that feed\n",
            "the retina become damaged in different ways. The dam-\n",
            "aged vessels can have bulges in their walls (aneurysms),\n",
            "they can leak blood into the surrounding jelly-like material\n",
            "(vitreous) that fills the inside of the eyeball, they can\n",
            "become completely closed, or new vessels can begin to\n",
            "grow where there would not normally be blood vessels.\n",
            " \n",
            "\n",
            "the 2th similar content :\n",
            " \n",
            " about 10 years after the beginning of diabetes. In the Unit-\n",
            "ed States, new cases of blindness are most often caused by\n",
            "diabetic retinopathy. Among these new cases of blindness,\n",
            "12% are people between the ages of 20 to 44 years, and\n",
            "19% are people between the ages of 45 to 64 years.\n",
            "Causes and symptoms\n",
            "There are many causes of retinopathy. Some of the\n",
            "more common ones are listed below.\n",
            "Diabetic retinopathy\n",
            "Diabetes is a complex disorder characterized by an\n",
            "inability of the body to properly regulate the levels of\n",
            "sugar and insulin (a hormone made by the pancreas) in the\n",
            "blood. As diabetes progresses, the blood vessels that feed\n",
            "the retina become damaged in different ways. The dam-\n",
            "aged vessels can have bulges in their walls (aneurysms),\n",
            "they can leak blood into the surrounding jelly-like material\n",
            "(vitreous) that fills the inside of the eyeball, they can\n",
            "become completely closed, or new vessels can begin to\n",
            "grow where there would not normally be blood vessels.\n",
            " \n",
            "\n",
            "the 3th similar content :\n",
            " \n",
            " sure to have thorough, periodic eye exams, especially if\n",
            "early signs of visual impairment are noticed. Anyone\n",
            "experiencing a sudden loss of vision, decrease in vision\n",
            "or visual field, flashes of light, or floating spots should\n",
            "contact their eye doctor right away.\n",
            "Proper medical treatment for any of the systemic\n",
            "diseases known to cause retinal damage will help prevent\n",
            "retinopathy. For diabetics, maintaining proper blood\n",
            "sugar and blood pressure levels is important as well;\n",
            "however, some form of retinopathy will usually occur in\n",
            "diabetics, given enough time. A proper diet, particularly\n",
            "for those persons with diabetes, and stopping smoking\n",
            "will also help delay retinopathy.\n",
            "Frequent, thorough eye exams and control of sys-\n",
            "temic disorders are the best prevention.\n",
            "Resources\n",
            "BOOKS\n",
            "Foster, Daniel, W. “Diabetes Mellitus.” In Harrison’s Princi-\n",
            "ples of Internal Medicine, ed. Anthony S. Fauci, et al.\n",
            "New York: McGraw-Hill, 1997.\n",
            "Horton, Jonathan, C. “Disorders of the Eye.” In Harrison’s\n",
            " \n",
            "\n",
            "the 4th similar content :\n",
            " \n",
            " sure to have thorough, periodic eye exams, especially if\n",
            "early signs of visual impairment are noticed. Anyone\n",
            "experiencing a sudden loss of vision, decrease in vision\n",
            "or visual field, flashes of light, or floating spots should\n",
            "contact their eye doctor right away.\n",
            "Proper medical treatment for any of the systemic\n",
            "diseases known to cause retinal damage will help prevent\n",
            "retinopathy. For diabetics, maintaining proper blood\n",
            "sugar and blood pressure levels is important as well;\n",
            "however, some form of retinopathy will usually occur in\n",
            "diabetics, given enough time. A proper diet, particularly\n",
            "for those persons with diabetes, and stopping smoking\n",
            "will also help delay retinopathy.\n",
            "Frequent, thorough eye exams and control of sys-\n",
            "temic disorders are the best prevention.\n",
            "Resources\n",
            "BOOKS\n",
            "Foster, Daniel, W. “Diabetes Mellitus.” In Harrison’s Princi-\n",
            "ples of Internal Medicine, ed. Anthony S. Fauci, et al.\n",
            "New York: McGraw-Hill, 1997.\n",
            "Horton, Jonathan, C. “Disorders of the Eye.” In Harrison’s\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Multi Query"
      ],
      "metadata": {
        "id": "89A1z2lWq5Sh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we create multiple versions of a question to capture different perspectives or possible interpretations. This improves retrieval diversity."
      ],
      "metadata": {
        "id": "T_qWv1HVtR2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")"
      ],
      "metadata": {
        "id": "orNJia1-OmYe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Multi Query: Different Perspectives\n",
        "template = \"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "different versions of the given user question to retrieve relevant documents from a vector\n",
        "database. By generating multiple perspectives on the user question, your goal is to help\n",
        "the user overcome some of the limitations of the distance-based similarity search.\n",
        "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
        "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "generate_queries = (\n",
        "    prompt_perspectives\n",
        "    | ChatOpenAI(temperature=0)\n",
        "    | StrOutputParser()\n",
        "    | (lambda x: x.split(\"\\n\"))\n",
        ")"
      ],
      "metadata": {
        "id": "gN9BOQnyiouH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_queries.invoke(\"what's diabetes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo2Z2-8Zitvf",
        "outputId": "527ddcb2-7263-4a4f-970c-3c6bd6ebeaac"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. Can you provide information on diabetes?',\n",
              " '2. What are the key aspects of diabetes that I should know about?',\n",
              " '3. Could you explain the causes and symptoms of diabetes?',\n",
              " '4. What are the different types of diabetes and their effects on the body?',\n",
              " '5. How can diabetes be managed and treated effectively?']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.load import dumps, loads\n",
        "\n",
        "def get_unique_union(documents: list[list]):\n",
        "    \"\"\" Unique union of retrieved docs \"\"\"\n",
        "    # Flatten list of lists, and convert each Document to string\n",
        "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
        "    # Get unique documents\n",
        "    unique_docs = list(set(flattened_docs))\n",
        "    return [loads(doc) for doc in unique_docs]\n",
        "\n",
        "# Retrieve\n",
        "question = \"What's diabetes'?\"\n",
        "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
        "docs = retrieval_chain.invoke({\"question\":question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJaEMNOijBN2",
        "outputId": "e90e306b-6aa1-4204-b884-f6cfc1fbf2db"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(docs)):\n",
        "  print(f\"{i+1}. {docs[1].page_content}\\n \\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVNZgahdjD82",
        "outputId": "34bc0ad6-3de1-4385-e918-9933b291110e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. myasthenia gravis. This type of polyglandular defi-\n",
            "ciency syndrome often produces insulin-dependent dia-\n",
            "betes mellitus (IDDM).\n",
            "• Type III disease may produce diabetes or adrenal fail-\n",
            "ure combined with thyroid problems. It may also\n",
            "include baldness (alopecia), anemia, and vitiligo (con-\n",
            "dition characterized by white patches on normally pig-\n",
            "mented skin).\n",
            "Not all symptoms of any syndrome appear at once or\n",
            "in the same patient.\n",
            "Diagnosis\n",
            "Because these diseases evolve over time, the final\n",
            "diagnosis may not appear for years. A family history is\n",
            "very helpful in knowing what to expect. Any single\n",
            "endocrine abnormality should heighten suspicion that\n",
            "KEY TERMS\n",
            "Antibody —A weapon in the body’s immune\n",
            "defense arsenal that attacks a specific antigen.\n",
            "Congenital—Present at birth.\n",
            "Myasthenia gravis—A disease that causes muscle\n",
            "weakness.\n",
            "Rubella—German measles.\n",
            "Syndrome —A collection of abnormalities that\n",
            "occur often enough to suggest they have a com-\n",
            "mon cause.\n",
            " \n",
            "\n",
            "2. myasthenia gravis. This type of polyglandular defi-\n",
            "ciency syndrome often produces insulin-dependent dia-\n",
            "betes mellitus (IDDM).\n",
            "• Type III disease may produce diabetes or adrenal fail-\n",
            "ure combined with thyroid problems. It may also\n",
            "include baldness (alopecia), anemia, and vitiligo (con-\n",
            "dition characterized by white patches on normally pig-\n",
            "mented skin).\n",
            "Not all symptoms of any syndrome appear at once or\n",
            "in the same patient.\n",
            "Diagnosis\n",
            "Because these diseases evolve over time, the final\n",
            "diagnosis may not appear for years. A family history is\n",
            "very helpful in knowing what to expect. Any single\n",
            "endocrine abnormality should heighten suspicion that\n",
            "KEY TERMS\n",
            "Antibody —A weapon in the body’s immune\n",
            "defense arsenal that attacks a specific antigen.\n",
            "Congenital—Present at birth.\n",
            "Myasthenia gravis—A disease that causes muscle\n",
            "weakness.\n",
            "Rubella—German measles.\n",
            "Syndrome —A collection of abnormalities that\n",
            "occur often enough to suggest they have a com-\n",
            "mon cause.\n",
            " \n",
            "\n",
            "3. myasthenia gravis. This type of polyglandular defi-\n",
            "ciency syndrome often produces insulin-dependent dia-\n",
            "betes mellitus (IDDM).\n",
            "• Type III disease may produce diabetes or adrenal fail-\n",
            "ure combined with thyroid problems. It may also\n",
            "include baldness (alopecia), anemia, and vitiligo (con-\n",
            "dition characterized by white patches on normally pig-\n",
            "mented skin).\n",
            "Not all symptoms of any syndrome appear at once or\n",
            "in the same patient.\n",
            "Diagnosis\n",
            "Because these diseases evolve over time, the final\n",
            "diagnosis may not appear for years. A family history is\n",
            "very helpful in knowing what to expect. Any single\n",
            "endocrine abnormality should heighten suspicion that\n",
            "KEY TERMS\n",
            "Antibody —A weapon in the body’s immune\n",
            "defense arsenal that attacks a specific antigen.\n",
            "Congenital—Present at birth.\n",
            "Myasthenia gravis—A disease that causes muscle\n",
            "weakness.\n",
            "Rubella—German measles.\n",
            "Syndrome —A collection of abnormalities that\n",
            "occur often enough to suggest they have a com-\n",
            "mon cause.\n",
            " \n",
            "\n",
            "4. myasthenia gravis. This type of polyglandular defi-\n",
            "ciency syndrome often produces insulin-dependent dia-\n",
            "betes mellitus (IDDM).\n",
            "• Type III disease may produce diabetes or adrenal fail-\n",
            "ure combined with thyroid problems. It may also\n",
            "include baldness (alopecia), anemia, and vitiligo (con-\n",
            "dition characterized by white patches on normally pig-\n",
            "mented skin).\n",
            "Not all symptoms of any syndrome appear at once or\n",
            "in the same patient.\n",
            "Diagnosis\n",
            "Because these diseases evolve over time, the final\n",
            "diagnosis may not appear for years. A family history is\n",
            "very helpful in knowing what to expect. Any single\n",
            "endocrine abnormality should heighten suspicion that\n",
            "KEY TERMS\n",
            "Antibody —A weapon in the body’s immune\n",
            "defense arsenal that attacks a specific antigen.\n",
            "Congenital—Present at birth.\n",
            "Myasthenia gravis—A disease that causes muscle\n",
            "weakness.\n",
            "Rubella—German measles.\n",
            "Syndrome —A collection of abnormalities that\n",
            "occur often enough to suggest they have a com-\n",
            "mon cause.\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Generate"
      ],
      "metadata": {
        "id": "ihvOCROsrLqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We process the retrieved information to generate a response using a language model, enhancing the chatbot's ability to answer complex queries."
      ],
      "metadata": {
        "id": "Stfonvf2tcJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "\n",
        "# RAG template\n",
        "template = \"\"\"Answer the following question based on this context and previous conversation:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Chat history:\n",
        "{chat_history}\n",
        "\n",
        "New human question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Initialize model and memory\n",
        "llm = ChatOpenAI(temperature=1)\n",
        "memory = ConversationBufferWindowMemory(k = 3, memory_key=\"chat_history\")\n",
        "\n",
        "# Define RAG pipeline without memory directly\n",
        "final_rag_chain = (\n",
        "    {\"context\": itemgetter(\"context\"),\n",
        "     \"question\": itemgetter(\"question\"),\n",
        "     \"chat_history\": itemgetter(\"chat_history\")}  # Include chat_history as a key here\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Retrieve the chat history from memory and include it in the input\n",
        "def invoke_with_memory(question, retrieval_chain):\n",
        "    # Load current chat history from memory\n",
        "    chat_history = memory.load_memory_variables({}).get(\"chat_history\", \"\")\n",
        "    result = final_rag_chain.invoke({\n",
        "        \"question\": question,\n",
        "        \"context\": retrieval_chain,  # Assuming retrieval_chain is defined elsewhere\n",
        "        \"chat_history\": chat_history,\n",
        "    })\n",
        "    # Update memory with the new interaction\n",
        "    memory.save_context({\"question\": question}, {\"answer\": result})\n",
        "    return result\n",
        "\n",
        "# Example call\n",
        "invoke_with_memory(\"what's diabetes?\", retrieval_chain=retrieval_chain)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "LN95rTj4y3fn",
        "outputId": "d0d270a6-191f-4f36-f411-99ccb5862552"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-3cec6a89ca2b>:24: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferWindowMemory(k = 3, memory_key=\"chat_history\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Diabetes is a complex disorder characterized by an inability of the body to properly regulate the levels of sugar and insulin in the blood.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "invoke_with_memory(\"what's its cause?\", retrieval_chain=retrieval_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oZSCdIWP0DFH",
        "outputId": "a169818e-e3e6-4767-d625-35f463b2fa22"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the context provided, the cause of disorders like somatoform disorders and paraphilias can be influenced by factors such as unconscious reflection or imitation of parental behaviors, cultural influences, biological factors, difficulty forming personal relationships, childhood trauma, and conditioning.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. UI"
      ],
      "metadata": {
        "id": "QQ7ojI-urT-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we build a simple interface with Gradio to interact with the medical chatbot. Users can type questions, and the chatbot will respond with relevant information."
      ],
      "metadata": {
        "id": "NI-Efiqhti5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "def medical_chatbot(query):\n",
        "    global chat_history\n",
        "\n",
        "    response = invoke_with_memory(query, retrieval_chain)\n",
        "    response = response.replace(\"Based on the context and previous conversation, \", \"\")\n",
        "    response = response.replace(\"Based on the conversation and context provided, \", \"\")\n",
        "    response = response.replace(\"Based on our previous conversation,\", \"\")\n",
        "    response = response.replace(\"Based on the context provided and our previous conversation,\", \"\")\n",
        "\n",
        "\n",
        "    chat_history.append((query, response))\n",
        "\n",
        "    return chat_history\n",
        "\n",
        "def reset_conversation():\n",
        "    global chat_history\n",
        "    chat_history = []\n",
        "    memory.aclear()\n",
        "    return chat_history\n",
        "\n",
        "with gr.Blocks() as interface:\n",
        "    gr.Markdown(\"# Medical Chatbot Assistant\")\n",
        "    gr.Markdown(\"Ask me any medical question, and I'll try to provide helpful information based on the provided data.\")\n",
        "\n",
        "    chatbot = gr.Chatbot()\n",
        "    query = gr.Textbox(label=\"Your Question\", placeholder=\"Type your medical question here...\")\n",
        "\n",
        "    submit_button = gr.Button(\"Get Answer\")\n",
        "    reset_button = gr.Button(\"Start New Conversation\")\n",
        "\n",
        "    submit_button.click(fn=medical_chatbot, inputs=query, outputs=chatbot)\n",
        "    reset_button.click(fn=reset_conversation, inputs=None, outputs=chatbot)\n",
        "\n",
        "    submit_button.click(lambda: \"\", None, query)\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "OKXu96koYNP1",
        "outputId": "d44e8c4b-256f-4c38-de9d-3b344b544931"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://84a3d3c458fd6b3f4f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://84a3d3c458fd6b3f4f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}
